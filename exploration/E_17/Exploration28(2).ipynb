{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 : 개구리는 안돼요! (CIFAR-10)\n",
    "\n",
    "이번 프로젝트는 지금까지의 실습과 동일한 방법으로 CIFAR-10 데이터셋에 대해 진행해보겠습니다.\n",
    "\n",
    "만들 모델은 CIFAR-10의 10가지 클래스 중 개구리 라벨을 이상 데이터로 처리하는 모델입니다. 혹시 개구리가 출현할 경우 이를 감지하여 이상감지 경과를 발생시키는 개구리 감지 모델이라고 할 수 있겠습니다.\n",
    "\n",
    "아래 순서를 따라 진행해주세요.\n",
    "\n",
    "- 이상 감지용 데이터셋 구축 (개구리 데이터를 학습 데이터셋에서 제외하며 테스트 데이터셋에 포함)\n",
    "- Skip-GANomaly 모델의 구현\n",
    "- 모델의 학습과 검증\n",
    "- 검증 결과의 시각화 (정상 - 이상 데이터의 anomaly score 분포 시각화, 적절한 threshold에 따른 이상감지율 계산, 감지 성공/실패 사례 시각화 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 모듈 import\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "from scipy.interpolate import interp1d\n",
    "from inspect import signature\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 이상감지 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_data = (train_data - 127.5) / 127.5\n",
    "test_data = (test_data - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_data[i])\n",
    "    plt.title(f'index:{i}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개구리 라벨은 6번입니다. 이상 데이터로 선정된 6번 라벨 데이터를 제외하도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels(labels):\n",
    "    new_t_labels = []\n",
    "    for old_label in labels:\n",
    "        if old_label == 6:\n",
    "            #print(old_label)\n",
    "            new_t_labels.append([0]) # 이상치로 처리\n",
    "        else:\n",
    "            new_t_labels.append([1])\n",
    "    return new_t_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bol_train_labels = set_labels(train_labels)\n",
    "bol_test_labels = set_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = []\n",
    "normal_labels = []\n",
    "anomaly_data = []\n",
    "anomaly_labels = []\n",
    "\n",
    "for data, label in zip(train_data, bol_train_labels):\n",
    "    if label == [0]:\n",
    "        anomaly_data.append(data)\n",
    "        anomaly_labels.append(label)\n",
    "    else:\n",
    "        normal_data.append(data)\n",
    "        normal_labels.append(label)\n",
    "        \n",
    "normal_data = np.array(normal_data)\n",
    "normal_labels = np.array(normal_labels)\n",
    "anomaly_data = np.array(anomaly_data)\n",
    "anomaly_labels = np.array(anomaly_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3) (45000, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(normal_data.shape, normal_labels.shape)\n",
    "print(anomaly_data.shape, anomaly_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normal_data\n",
    "bol_train_labels = normal_labels\n",
    "test_data = tf.concat([test_data, anomaly_data], 0)\n",
    "bol_test_labels = tf.concat([bol_test_labels, anomaly_labels], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n",
      "(15000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 1)\n",
      "(15000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(bol_train_labels.shape)\n",
    "print(bol_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50000건의 데이터를 잘 나눈 것 같습니다. 개구리만 5000장이나 있네요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for label in bol_train_labels:\n",
    "    if label == 0:\n",
    "        print(label)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 구성하고 label을 검증해봅시다. \n",
    "\n",
    "훈련 데이터셋에는 라벨이 1인 데이터만 존재하고 테스트 데이터에는 0과 1이 섞여있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, bol_train_labels))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, bol_test_labels))\n",
    "test_dataset = test_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]], shape=(8, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_dataset.take(1):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]], shape=(8, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for data, label in test_dataset.take(1):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Skip-GANomaly 모델의 구현\n",
    "\n",
    "\n",
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_block(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.conv_layer = tf.keras.Sequential([\n",
    "            layers.Conv2D(num_filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                          kernel_initializer=tf.random_normal_initializer(0., 0.02)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        outputs = self.conv_layer(inputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_T_block(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(Conv_T_block, self).__init__()\n",
    "        self.conv_T_layer = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(num_filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                                   kernel_initializer=tf.random_normal_initializer(0., 0.02)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs, concat, training=False):\n",
    "        upsample = self.conv_T_layer(inputs)\n",
    "        outputs = tf.concat([upsample, concat], -1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, num_output_channel = 3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.encoder_1 = Conv_block(64) # 16\n",
    "        self.encoder_2 = Conv_block(128) # 8\n",
    "        self.encoder_3 = Conv_block(256) # 4\n",
    "        self.encoder_4 = Conv_block(512) # 2\n",
    "        \n",
    "        self.center = Conv_block(512) # 1\n",
    "        \n",
    "        self.decoder_4 = Conv_T_block(512) # 2\n",
    "        self.decoder_3 = Conv_T_block(256) # 4\n",
    "        self.decoder_2 = Conv_T_block(128) # 8\n",
    "        self.decoder_1 = Conv_T_block(64) # 16\n",
    "        \n",
    "        self.output_layer = layers.Conv2DTranspose(num_output_channel, 1, strides=2,\n",
    "                                                  padding='same', use_bias=False,\n",
    "                                                  kernel_initializer=tf.random_normal_initializer(0., 0.02))\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        en_1 = self.encoder_1(inputs) # gen\n",
    "        en_2 = self.encoder_2(en_1)\n",
    "        en_3 = self.encoder_3(en_2)\n",
    "        en_4 = self.encoder_4(en_3)\n",
    "        \n",
    "        center = self.center(en_4)\n",
    "        \n",
    "        de_4 = self.decoder_4(center, en_4)\n",
    "        de_3 = self.decoder_3(de_4, en_3)\n",
    "        de_2 = self.decoder_2(de_3, en_2)\n",
    "        de_1 = self.decoder_1(de_2, en_1)\n",
    "        \n",
    "        outputs = self.output_layer(de_1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "Discriminator도 Generator처럼 Conv_block을 활용하며, 최종적으로 sigmoid를 거쳐 0~1 사이의 숫자를 리턴합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.encoder_1 = Conv_block(64) # 16\n",
    "        self.encoder_2 = Conv_block(128) # 8\n",
    "        self.encoder_3 = Conv_block(256) # 4\n",
    "        self.encoder_4 = Conv_block(512) # 2\n",
    "        \n",
    "        self.center = Conv_block(100) # 1\n",
    "        \n",
    "        self.outputs = layers.Conv2D(1, 3, strides=1, padding='same',\n",
    "                                    use_bias = False, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        en_1 = self.encoder_1(inputs) # dis\n",
    "        en_2 = self.encoder_2(en_1)\n",
    "        en_3 = self.encoder_3(en_2)\n",
    "        en_4 = self.encoder_4(en_3)\n",
    "        \n",
    "        center = self.center(en_4)\n",
    "        \n",
    "        outputs = self.outputs(center)\n",
    "        \n",
    "        return outputs, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(num_output_channel=3)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss 함수\n",
    "\n",
    "GAN 모델의 핵심은 Loss 함수의 구성방법에 달려 있다고 해도 과언이 아닙니다. Skip-GANomaly는 이전 모델들과 달리 일반적인 GAN의 학습 절차와 같은 형태의 Loss 구성이 진행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_loss = tf.keras.losses.MeanSquaredError()\n",
    "l1_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(pred_real, pred_fake):\n",
    "    real_loss = cross_entropy(tf.ones_like(pred_real), pred_real)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(pred_fake), pred_fake)\n",
    "    \n",
    "    total_dis_loss = (real_loss + fake_loss) * 0.5\n",
    "    \n",
    "    return total_dis_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(real_output, fake_output, \n",
    "                   input_data, gen_data, \n",
    "                   latent_first, latent_sec):\n",
    "    w_adv = 1.\n",
    "    w_context = 40.\n",
    "    w_encoder = 1.\n",
    "    \n",
    "    adv_loss = cross_entropy(real_output, fake_output)\n",
    "    context_loss = l1_loss(input_data, gen_data)\n",
    "    encoder_loss = l2_loss(latent_first, latent_sec)\n",
    "    \n",
    "    total_gen_loss = w_adv * adv_loss + \\\n",
    "        w_context * context_loss + \\\n",
    "        w_encoder * encoder_loss\n",
    "\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 설정\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-3, 0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-3, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 모델 학습과 검증\n",
    "\n",
    "### Model Train\n",
    "\n",
    "본격적으로 모델을 학습시켜봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(images, training=True)\n",
    "        \n",
    "        pred_real, feat_real = discriminator(images, training=True)\n",
    "        pred_fake, feat_fake = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(pred_real, pred_fake,\n",
    "                                  images, generated_images,\n",
    "                                  feat_real, feat_fake)\n",
    "\n",
    "        disc_loss = discriminator_loss(pred_real, pred_fake)        \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(os.getenv('HOME'),'aiffel/ganomaly_skip_no_norm/ckpt')\n",
    "\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 100, \t Total Gen Loss : 26.599557876586914, \t Total Dis Loss : 0.001720196334645152\n",
      "Steps : 200, \t Total Gen Loss : 28.153732299804688, \t Total Dis Loss : 0.004021925386041403\n",
      "Steps : 300, \t Total Gen Loss : 24.85429573059082, \t Total Dis Loss : 0.0010040960041806102\n",
      "Steps : 400, \t Total Gen Loss : 20.88897132873535, \t Total Dis Loss : 0.002625041175633669\n",
      "Steps : 500, \t Total Gen Loss : 23.213520050048828, \t Total Dis Loss : 0.001350597944110632\n",
      "Steps : 600, \t Total Gen Loss : 21.140586853027344, \t Total Dis Loss : 0.001834370894357562\n",
      "Steps : 700, \t Total Gen Loss : 26.333003997802734, \t Total Dis Loss : 0.0006029372452758253\n",
      "Steps : 800, \t Total Gen Loss : 20.940448760986328, \t Total Dis Loss : 0.002944812411442399\n",
      "Steps : 900, \t Total Gen Loss : 20.459575653076172, \t Total Dis Loss : 0.0008829345460981131\n",
      "Steps : 1000, \t Total Gen Loss : 19.959625244140625, \t Total Dis Loss : 0.005904758349061012\n",
      "Steps : 1100, \t Total Gen Loss : 27.42235565185547, \t Total Dis Loss : 0.00421613734215498\n",
      "Steps : 1200, \t Total Gen Loss : 29.11911964416504, \t Total Dis Loss : 0.0016920567722991109\n",
      "Steps : 1300, \t Total Gen Loss : 21.430105209350586, \t Total Dis Loss : 0.003542534075677395\n",
      "Steps : 1400, \t Total Gen Loss : 20.60399055480957, \t Total Dis Loss : 0.0009524609777145088\n",
      "Steps : 1500, \t Total Gen Loss : 24.248966217041016, \t Total Dis Loss : 0.0005390639416873455\n",
      "Steps : 1600, \t Total Gen Loss : 19.74721336364746, \t Total Dis Loss : 0.001399834407493472\n",
      "Steps : 1700, \t Total Gen Loss : 21.95838737487793, \t Total Dis Loss : 0.0005691663245670497\n",
      "Steps : 1800, \t Total Gen Loss : 23.65198516845703, \t Total Dis Loss : 0.0002057527017313987\n",
      "Steps : 1900, \t Total Gen Loss : 25.81576919555664, \t Total Dis Loss : 0.0008213297696784139\n",
      "Steps : 2000, \t Total Gen Loss : 21.9221248626709, \t Total Dis Loss : 0.0007677294779568911\n",
      "Steps : 2100, \t Total Gen Loss : 24.939218521118164, \t Total Dis Loss : 0.0002714114380069077\n",
      "Steps : 2200, \t Total Gen Loss : 27.793542861938477, \t Total Dis Loss : 0.0016172714531421661\n",
      "Steps : 2300, \t Total Gen Loss : 22.98529815673828, \t Total Dis Loss : 0.0010953157907351851\n",
      "Steps : 2400, \t Total Gen Loss : 22.24456024169922, \t Total Dis Loss : 0.0013962864177301526\n",
      "Steps : 2500, \t Total Gen Loss : 27.964981079101562, \t Total Dis Loss : 0.00022852835536468774\n",
      "Steps : 2600, \t Total Gen Loss : 26.321544647216797, \t Total Dis Loss : 0.0006182339857332408\n",
      "Steps : 2700, \t Total Gen Loss : 25.149824142456055, \t Total Dis Loss : 0.000311411393340677\n",
      "Steps : 2800, \t Total Gen Loss : 26.683795928955078, \t Total Dis Loss : 0.0022857312578707933\n",
      "Steps : 2900, \t Total Gen Loss : 23.810871124267578, \t Total Dis Loss : 0.0008667565416544676\n",
      "Steps : 3000, \t Total Gen Loss : 25.002010345458984, \t Total Dis Loss : 0.0003341787087265402\n",
      "Steps : 3100, \t Total Gen Loss : 22.122806549072266, \t Total Dis Loss : 0.0009254190954379737\n",
      "Steps : 3200, \t Total Gen Loss : 26.55274200439453, \t Total Dis Loss : 0.0006738740485161543\n",
      "Steps : 3300, \t Total Gen Loss : 22.704744338989258, \t Total Dis Loss : 0.0008661611936986446\n",
      "Steps : 3400, \t Total Gen Loss : 24.275733947753906, \t Total Dis Loss : 0.0005399457877501845\n",
      "Steps : 3500, \t Total Gen Loss : 28.223814010620117, \t Total Dis Loss : 0.0001521299418527633\n",
      "Steps : 3600, \t Total Gen Loss : 26.042631149291992, \t Total Dis Loss : 0.00014732852287124842\n",
      "Steps : 3700, \t Total Gen Loss : 28.82793617248535, \t Total Dis Loss : 0.0001235880481544882\n",
      "Steps : 3800, \t Total Gen Loss : 24.450897216796875, \t Total Dis Loss : 0.00039540795842185616\n",
      "Steps : 3900, \t Total Gen Loss : 25.377784729003906, \t Total Dis Loss : 0.00018730292504187673\n",
      "Steps : 4000, \t Total Gen Loss : 25.08708381652832, \t Total Dis Loss : 0.0005937155801802874\n",
      "Steps : 4100, \t Total Gen Loss : 24.01190948486328, \t Total Dis Loss : 0.0012123767519369721\n",
      "Steps : 4200, \t Total Gen Loss : 24.41107940673828, \t Total Dis Loss : 0.0005456632934510708\n",
      "Steps : 4300, \t Total Gen Loss : 26.343107223510742, \t Total Dis Loss : 0.0005289653199724853\n",
      "Steps : 4400, \t Total Gen Loss : 23.007553100585938, \t Total Dis Loss : 0.001168751041404903\n",
      "Steps : 4500, \t Total Gen Loss : 25.07125473022461, \t Total Dis Loss : 0.0003136644372716546\n",
      "Steps : 4600, \t Total Gen Loss : 23.836891174316406, \t Total Dis Loss : 0.0003545584040693939\n",
      "Steps : 4700, \t Total Gen Loss : 22.298837661743164, \t Total Dis Loss : 0.001004094840027392\n",
      "Steps : 4800, \t Total Gen Loss : 22.757915496826172, \t Total Dis Loss : 0.0005019289092160761\n",
      "Steps : 4900, \t Total Gen Loss : 26.1291561126709, \t Total Dis Loss : 0.00031808140920475125\n",
      "Steps : 5000, \t Total Gen Loss : 27.164453506469727, \t Total Dis Loss : 0.0004055490717291832\n",
      "Steps : 5100, \t Total Gen Loss : 29.49431800842285, \t Total Dis Loss : 0.0002952858048956841\n",
      "Steps : 5200, \t Total Gen Loss : 21.98861312866211, \t Total Dis Loss : 0.00044910257565788925\n",
      "Steps : 5300, \t Total Gen Loss : 24.379840850830078, \t Total Dis Loss : 0.0004180007672403008\n",
      "Steps : 5400, \t Total Gen Loss : 25.518943786621094, \t Total Dis Loss : 0.000803553790319711\n",
      "Steps : 5500, \t Total Gen Loss : 24.255268096923828, \t Total Dis Loss : 0.0004023521323688328\n",
      "Steps : 5600, \t Total Gen Loss : 23.337820053100586, \t Total Dis Loss : 0.0004034177400171757\n",
      "Time for epoch 1 is 286.9764955043793 sec\n",
      "Steps : 5700, \t Total Gen Loss : 27.127593994140625, \t Total Dis Loss : 0.00018003841978497803\n",
      "Steps : 5800, \t Total Gen Loss : 27.123714447021484, \t Total Dis Loss : 0.001025420962832868\n",
      "Steps : 5900, \t Total Gen Loss : 26.011232376098633, \t Total Dis Loss : 0.0023044883273541927\n",
      "Steps : 6000, \t Total Gen Loss : 21.130821228027344, \t Total Dis Loss : 0.007175549864768982\n",
      "Steps : 6100, \t Total Gen Loss : 24.328210830688477, \t Total Dis Loss : 0.0011649582302197814\n",
      "Steps : 6200, \t Total Gen Loss : 25.599437713623047, \t Total Dis Loss : 0.0012651355937123299\n",
      "Steps : 6300, \t Total Gen Loss : 25.621267318725586, \t Total Dis Loss : 0.00184870813973248\n",
      "Steps : 6400, \t Total Gen Loss : 26.466670989990234, \t Total Dis Loss : 0.0005281581543385983\n",
      "Steps : 6500, \t Total Gen Loss : 25.517080307006836, \t Total Dis Loss : 0.0010213806526735425\n",
      "Steps : 6600, \t Total Gen Loss : 29.21238136291504, \t Total Dis Loss : 0.0006706487038172781\n",
      "Steps : 6700, \t Total Gen Loss : 23.471452713012695, \t Total Dis Loss : 0.0008800351060926914\n",
      "Steps : 6800, \t Total Gen Loss : 24.828983306884766, \t Total Dis Loss : 0.010707834735512733\n",
      "Steps : 6900, \t Total Gen Loss : 20.860610961914062, \t Total Dis Loss : 0.001889907754957676\n",
      "Steps : 7000, \t Total Gen Loss : 24.632160186767578, \t Total Dis Loss : 0.0007884145015850663\n",
      "Steps : 7100, \t Total Gen Loss : 24.164880752563477, \t Total Dis Loss : 0.00035896903136745095\n",
      "Steps : 7200, \t Total Gen Loss : 24.017940521240234, \t Total Dis Loss : 0.00034547297400422394\n",
      "Steps : 7300, \t Total Gen Loss : 26.998268127441406, \t Total Dis Loss : 0.00023445246915798634\n",
      "Steps : 7400, \t Total Gen Loss : 24.399782180786133, \t Total Dis Loss : 0.0003375682863406837\n",
      "Steps : 7500, \t Total Gen Loss : 23.897926330566406, \t Total Dis Loss : 0.00037405636976473033\n",
      "Steps : 7600, \t Total Gen Loss : 23.344627380371094, \t Total Dis Loss : 0.0004121075035072863\n",
      "Steps : 7700, \t Total Gen Loss : 26.49951171875, \t Total Dis Loss : 0.0002988019259646535\n",
      "Steps : 7800, \t Total Gen Loss : 23.6755313873291, \t Total Dis Loss : 0.00017638361896388233\n",
      "Steps : 7900, \t Total Gen Loss : 24.79947280883789, \t Total Dis Loss : 0.0002618427388370037\n",
      "Steps : 8000, \t Total Gen Loss : 24.69873046875, \t Total Dis Loss : 0.00025044436915777624\n",
      "Steps : 8100, \t Total Gen Loss : 22.999155044555664, \t Total Dis Loss : 0.000731199630536139\n",
      "Steps : 8200, \t Total Gen Loss : 23.87934684753418, \t Total Dis Loss : 0.0008881506510078907\n",
      "Steps : 8300, \t Total Gen Loss : 23.510343551635742, \t Total Dis Loss : 0.016146717593073845\n",
      "Steps : 8400, \t Total Gen Loss : 23.56043815612793, \t Total Dis Loss : 0.0016361468005925417\n",
      "Steps : 8500, \t Total Gen Loss : 24.61322784423828, \t Total Dis Loss : 0.00039590016240254045\n",
      "Steps : 8600, \t Total Gen Loss : 23.668081283569336, \t Total Dis Loss : 0.0008098086691461504\n",
      "Steps : 8700, \t Total Gen Loss : 25.961009979248047, \t Total Dis Loss : 0.0010665906593203545\n",
      "Steps : 8800, \t Total Gen Loss : 23.161449432373047, \t Total Dis Loss : 0.0005123417358845472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 8900, \t Total Gen Loss : 22.987178802490234, \t Total Dis Loss : 0.0005946144228801131\n",
      "Steps : 9000, \t Total Gen Loss : 25.530370712280273, \t Total Dis Loss : 0.00040964604704640806\n",
      "Steps : 9100, \t Total Gen Loss : 23.11440086364746, \t Total Dis Loss : 0.0005223599728196859\n",
      "Steps : 9200, \t Total Gen Loss : 23.904560089111328, \t Total Dis Loss : 0.0008143869345076382\n",
      "Steps : 9300, \t Total Gen Loss : 24.018875122070312, \t Total Dis Loss : 0.0014595839893445373\n",
      "Steps : 9400, \t Total Gen Loss : 26.30617332458496, \t Total Dis Loss : 0.0011058237869292498\n",
      "Steps : 9500, \t Total Gen Loss : 22.738971710205078, \t Total Dis Loss : 0.0005065264413133264\n",
      "Steps : 9600, \t Total Gen Loss : 23.387592315673828, \t Total Dis Loss : 0.0006531958933919668\n",
      "Steps : 9700, \t Total Gen Loss : 23.168407440185547, \t Total Dis Loss : 0.00036161692696623504\n",
      "Steps : 9800, \t Total Gen Loss : 22.49827003479004, \t Total Dis Loss : 0.00041362910997122526\n",
      "Steps : 9900, \t Total Gen Loss : 23.352140426635742, \t Total Dis Loss : 0.00024041719734668732\n",
      "Steps : 10000, \t Total Gen Loss : 26.73719024658203, \t Total Dis Loss : 0.00020600893185473979\n",
      "Steps : 10100, \t Total Gen Loss : 23.445741653442383, \t Total Dis Loss : 4.794611595571041e-05\n",
      "Steps : 10200, \t Total Gen Loss : 25.726966857910156, \t Total Dis Loss : 0.0002884241403080523\n",
      "Steps : 10300, \t Total Gen Loss : 28.926307678222656, \t Total Dis Loss : 8.985630847746506e-05\n",
      "Steps : 10400, \t Total Gen Loss : 22.105545043945312, \t Total Dis Loss : 0.0012656472390517592\n",
      "Steps : 10500, \t Total Gen Loss : 25.502531051635742, \t Total Dis Loss : 0.0006314037018455565\n",
      "Steps : 10600, \t Total Gen Loss : 24.604124069213867, \t Total Dis Loss : 0.0005124612362124026\n",
      "Steps : 10700, \t Total Gen Loss : 23.435705184936523, \t Total Dis Loss : 0.00410133320838213\n",
      "Steps : 10800, \t Total Gen Loss : 25.530418395996094, \t Total Dis Loss : 0.006355092860758305\n",
      "Steps : 10900, \t Total Gen Loss : 25.92899513244629, \t Total Dis Loss : 0.0005199075676500797\n",
      "Steps : 11000, \t Total Gen Loss : 23.780109405517578, \t Total Dis Loss : 0.1666564792394638\n",
      "Steps : 11100, \t Total Gen Loss : 25.333385467529297, \t Total Dis Loss : 0.0010378067381680012\n",
      "Steps : 11200, \t Total Gen Loss : 26.94355583190918, \t Total Dis Loss : 0.0007453208090737462\n",
      "Time for epoch 2 is 273.38745498657227 sec\n",
      "Steps : 11300, \t Total Gen Loss : 23.782089233398438, \t Total Dis Loss : 0.0001802251790650189\n",
      "Steps : 11400, \t Total Gen Loss : 27.39478874206543, \t Total Dis Loss : 0.0005142830195836723\n",
      "Steps : 11500, \t Total Gen Loss : 30.708696365356445, \t Total Dis Loss : 9.543110354570672e-05\n",
      "Steps : 11600, \t Total Gen Loss : 24.748565673828125, \t Total Dis Loss : 0.00016460753977298737\n",
      "Steps : 11700, \t Total Gen Loss : 27.25909423828125, \t Total Dis Loss : 0.00021191808627918363\n",
      "Steps : 11800, \t Total Gen Loss : 25.903650283813477, \t Total Dis Loss : 0.00022342779266182333\n",
      "Steps : 11900, \t Total Gen Loss : 29.17430305480957, \t Total Dis Loss : 0.00014930925681255758\n",
      "Steps : 12000, \t Total Gen Loss : 30.683338165283203, \t Total Dis Loss : 0.000104617873148527\n",
      "Steps : 12100, \t Total Gen Loss : 26.40241813659668, \t Total Dis Loss : 0.0002488266909494996\n",
      "Steps : 12200, \t Total Gen Loss : 26.31416893005371, \t Total Dis Loss : 9.939754090737551e-05\n",
      "Steps : 12300, \t Total Gen Loss : 25.930063247680664, \t Total Dis Loss : 7.121865201042965e-05\n",
      "Steps : 12400, \t Total Gen Loss : 25.900835037231445, \t Total Dis Loss : 6.0793561715399846e-05\n",
      "Steps : 12500, \t Total Gen Loss : 23.484756469726562, \t Total Dis Loss : 0.0003124843933619559\n",
      "Steps : 12600, \t Total Gen Loss : 25.335847854614258, \t Total Dis Loss : 9.014952229335904e-05\n",
      "Steps : 12700, \t Total Gen Loss : 25.51736831665039, \t Total Dis Loss : 0.0002433498448226601\n",
      "Steps : 12800, \t Total Gen Loss : 29.0872745513916, \t Total Dis Loss : 6.019883949193172e-05\n",
      "Steps : 12900, \t Total Gen Loss : 26.631345748901367, \t Total Dis Loss : 0.00011956013622693717\n",
      "Steps : 13000, \t Total Gen Loss : 26.999454498291016, \t Total Dis Loss : 7.644046127097681e-05\n",
      "Steps : 13100, \t Total Gen Loss : 27.651308059692383, \t Total Dis Loss : 3.5957687941845506e-05\n",
      "Steps : 13200, \t Total Gen Loss : 27.608850479125977, \t Total Dis Loss : 7.489769632229581e-05\n",
      "Steps : 13300, \t Total Gen Loss : 27.710092544555664, \t Total Dis Loss : 3.048504368052818e-05\n",
      "Steps : 13400, \t Total Gen Loss : 25.3268985748291, \t Total Dis Loss : 0.00019784596224781126\n",
      "Steps : 13500, \t Total Gen Loss : 25.09433937072754, \t Total Dis Loss : 7.113386527635157e-05\n",
      "Steps : 13600, \t Total Gen Loss : 25.408226013183594, \t Total Dis Loss : 0.0005762373330071568\n",
      "Steps : 13700, \t Total Gen Loss : 25.4595890045166, \t Total Dis Loss : 0.00020869725267402828\n",
      "Steps : 13800, \t Total Gen Loss : 29.786930084228516, \t Total Dis Loss : 8.78515638760291e-05\n",
      "Steps : 13900, \t Total Gen Loss : 23.89722442626953, \t Total Dis Loss : 7.427255332004279e-05\n",
      "Steps : 14000, \t Total Gen Loss : 27.528470993041992, \t Total Dis Loss : 0.000321911764331162\n",
      "Steps : 14100, \t Total Gen Loss : 22.392663955688477, \t Total Dis Loss : 0.9380075335502625\n",
      "Steps : 14200, \t Total Gen Loss : 28.69622802734375, \t Total Dis Loss : 0.00011490353790577501\n",
      "Steps : 14300, \t Total Gen Loss : 27.558887481689453, \t Total Dis Loss : 0.0005367120029404759\n",
      "Steps : 14400, \t Total Gen Loss : 25.181251525878906, \t Total Dis Loss : 0.00166828534565866\n",
      "Steps : 14500, \t Total Gen Loss : 24.754032135009766, \t Total Dis Loss : 0.0016640563262626529\n",
      "Steps : 14600, \t Total Gen Loss : 25.27662467956543, \t Total Dis Loss : 0.0007745617185719311\n",
      "Steps : 14700, \t Total Gen Loss : 24.298879623413086, \t Total Dis Loss : 0.0004930494469590485\n",
      "Steps : 14800, \t Total Gen Loss : 29.417953491210938, \t Total Dis Loss : 0.0011049022432416677\n",
      "Steps : 14900, \t Total Gen Loss : 25.64998435974121, \t Total Dis Loss : 0.00028022975311614573\n",
      "Steps : 15000, \t Total Gen Loss : 29.763378143310547, \t Total Dis Loss : 0.0002650201495271176\n",
      "Steps : 15100, \t Total Gen Loss : 26.44646644592285, \t Total Dis Loss : 0.0011568828485906124\n",
      "Steps : 15200, \t Total Gen Loss : 23.729337692260742, \t Total Dis Loss : 0.06215095892548561\n",
      "Steps : 15300, \t Total Gen Loss : 32.324790954589844, \t Total Dis Loss : 0.0005048518069088459\n",
      "Steps : 15400, \t Total Gen Loss : 28.527620315551758, \t Total Dis Loss : 0.00093023048248142\n",
      "Steps : 15500, \t Total Gen Loss : 29.947792053222656, \t Total Dis Loss : 0.000142467106343247\n",
      "Steps : 15600, \t Total Gen Loss : 27.93657684326172, \t Total Dis Loss : 0.0011754429433494806\n",
      "Steps : 15700, \t Total Gen Loss : 27.014812469482422, \t Total Dis Loss : 0.0007425618823617697\n",
      "Steps : 15800, \t Total Gen Loss : 25.85155487060547, \t Total Dis Loss : 0.0002696700976230204\n",
      "Steps : 15900, \t Total Gen Loss : 24.52378273010254, \t Total Dis Loss : 0.0006210443680174649\n",
      "Steps : 16000, \t Total Gen Loss : 24.590402603149414, \t Total Dis Loss : 0.00030383747071027756\n",
      "Steps : 16100, \t Total Gen Loss : 23.4219970703125, \t Total Dis Loss : 0.00024120465968735516\n",
      "Steps : 16200, \t Total Gen Loss : 25.00858497619629, \t Total Dis Loss : 0.0002732591237872839\n",
      "Steps : 16300, \t Total Gen Loss : 26.398677825927734, \t Total Dis Loss : 0.005852260626852512\n",
      "Steps : 16400, \t Total Gen Loss : 25.85643196105957, \t Total Dis Loss : 0.0022408703807741404\n",
      "Steps : 16500, \t Total Gen Loss : 28.223928451538086, \t Total Dis Loss : 0.00018362168339081109\n",
      "Steps : 16600, \t Total Gen Loss : 25.590120315551758, \t Total Dis Loss : 9.141926420852542e-05\n",
      "Steps : 16700, \t Total Gen Loss : 26.28948211669922, \t Total Dis Loss : 0.0002814455365296453\n",
      "Steps : 16800, \t Total Gen Loss : 29.318553924560547, \t Total Dis Loss : 0.00014805517275817692\n",
      "Time for epoch 3 is 273.0527560710907 sec\n",
      "Steps : 16900, \t Total Gen Loss : 25.858917236328125, \t Total Dis Loss : 0.0001785287749953568\n",
      "Steps : 17000, \t Total Gen Loss : 26.555938720703125, \t Total Dis Loss : 0.00014769341214559972\n",
      "Steps : 17100, \t Total Gen Loss : 27.11279296875, \t Total Dis Loss : 0.000101952682598494\n",
      "Steps : 17200, \t Total Gen Loss : 27.6527042388916, \t Total Dis Loss : 5.390026490204036e-05\n",
      "Steps : 17300, \t Total Gen Loss : 27.949405670166016, \t Total Dis Loss : 0.25936606526374817\n",
      "Steps : 17400, \t Total Gen Loss : 28.704242706298828, \t Total Dis Loss : 0.0008756944444030523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 17500, \t Total Gen Loss : 25.47000503540039, \t Total Dis Loss : 0.00037722045090049505\n",
      "Steps : 17600, \t Total Gen Loss : 25.089515686035156, \t Total Dis Loss : 0.00013479817425832152\n",
      "Steps : 17700, \t Total Gen Loss : 25.119949340820312, \t Total Dis Loss : 0.00039011065382510424\n",
      "Steps : 17800, \t Total Gen Loss : 25.595638275146484, \t Total Dis Loss : 0.00010469598055351526\n",
      "Steps : 17900, \t Total Gen Loss : 25.220947265625, \t Total Dis Loss : 7.233826909214258e-05\n",
      "Steps : 18000, \t Total Gen Loss : 24.707977294921875, \t Total Dis Loss : 0.000280372507404536\n",
      "Steps : 18100, \t Total Gen Loss : 25.80998420715332, \t Total Dis Loss : 0.0005242583574727178\n",
      "Steps : 18200, \t Total Gen Loss : 27.511253356933594, \t Total Dis Loss : 0.00010227962047792971\n",
      "Steps : 18300, \t Total Gen Loss : 27.68001937866211, \t Total Dis Loss : 0.355838805437088\n",
      "Steps : 18400, \t Total Gen Loss : 26.55247688293457, \t Total Dis Loss : 0.001136715873144567\n",
      "Steps : 18500, \t Total Gen Loss : 29.292104721069336, \t Total Dis Loss : 0.002869179705157876\n",
      "Steps : 18600, \t Total Gen Loss : 26.93157196044922, \t Total Dis Loss : 0.00011831283336505294\n",
      "Steps : 18700, \t Total Gen Loss : 26.02071762084961, \t Total Dis Loss : 0.00034721093834377825\n",
      "Steps : 18800, \t Total Gen Loss : 23.330951690673828, \t Total Dis Loss : 0.003685194067656994\n",
      "Steps : 18900, \t Total Gen Loss : 25.836307525634766, \t Total Dis Loss : 0.00048641543253324926\n",
      "Steps : 19000, \t Total Gen Loss : 20.719493865966797, \t Total Dis Loss : 0.0015910661313682795\n",
      "Steps : 19100, \t Total Gen Loss : 24.387813568115234, \t Total Dis Loss : 0.0006593319121748209\n",
      "Steps : 19200, \t Total Gen Loss : 20.40176010131836, \t Total Dis Loss : 0.0009545966750010848\n",
      "Steps : 19300, \t Total Gen Loss : 22.543659210205078, \t Total Dis Loss : 0.0010448810644447803\n",
      "Steps : 19400, \t Total Gen Loss : 18.512863159179688, \t Total Dis Loss : 0.023330865427851677\n",
      "Steps : 19500, \t Total Gen Loss : 29.64577293395996, \t Total Dis Loss : 0.0003537118900567293\n",
      "Steps : 19600, \t Total Gen Loss : 23.506677627563477, \t Total Dis Loss : 0.0013865667860955\n",
      "Steps : 19700, \t Total Gen Loss : 21.768165588378906, \t Total Dis Loss : 0.00038778933230787516\n",
      "Steps : 19800, \t Total Gen Loss : 25.66421890258789, \t Total Dis Loss : 0.00022579729557037354\n",
      "Steps : 19900, \t Total Gen Loss : 25.115821838378906, \t Total Dis Loss : 0.0003537913435138762\n",
      "Steps : 20000, \t Total Gen Loss : 28.904279708862305, \t Total Dis Loss : 0.00021683381055481732\n",
      "Steps : 20100, \t Total Gen Loss : 25.474069595336914, \t Total Dis Loss : 0.00038590613985434175\n",
      "Steps : 20200, \t Total Gen Loss : 30.132028579711914, \t Total Dis Loss : 0.00010257968096993864\n",
      "Steps : 20300, \t Total Gen Loss : 22.07942771911621, \t Total Dis Loss : 0.0008752376306802034\n",
      "Steps : 20400, \t Total Gen Loss : 22.41107749938965, \t Total Dis Loss : 0.0012241783551871777\n",
      "Steps : 20500, \t Total Gen Loss : 24.713857650756836, \t Total Dis Loss : 0.00047574786003679037\n",
      "Steps : 20600, \t Total Gen Loss : 24.04389190673828, \t Total Dis Loss : 0.0004796982684638351\n",
      "Steps : 20700, \t Total Gen Loss : 26.762161254882812, \t Total Dis Loss : 0.00017855712212622166\n",
      "Steps : 20800, \t Total Gen Loss : 23.89592170715332, \t Total Dis Loss : 0.0003139167674817145\n",
      "Steps : 20900, \t Total Gen Loss : 28.067270278930664, \t Total Dis Loss : 0.00016073623555712402\n",
      "Steps : 21000, \t Total Gen Loss : 23.66693115234375, \t Total Dis Loss : 0.00023748379317112267\n",
      "Steps : 21100, \t Total Gen Loss : 23.459293365478516, \t Total Dis Loss : 0.00017430572188459337\n",
      "Steps : 21200, \t Total Gen Loss : 24.84054183959961, \t Total Dis Loss : 0.00010314100654795766\n",
      "Steps : 21300, \t Total Gen Loss : 22.68423080444336, \t Total Dis Loss : 0.00030684511875733733\n",
      "Steps : 21400, \t Total Gen Loss : 26.160289764404297, \t Total Dis Loss : 0.000278518651612103\n",
      "Steps : 21500, \t Total Gen Loss : 23.076805114746094, \t Total Dis Loss : 0.00018911511870101094\n",
      "Steps : 21600, \t Total Gen Loss : 27.185592651367188, \t Total Dis Loss : 0.00012690425501205027\n",
      "Steps : 21700, \t Total Gen Loss : 27.017314910888672, \t Total Dis Loss : 0.0005033472552895546\n",
      "Steps : 21800, \t Total Gen Loss : 26.023683547973633, \t Total Dis Loss : 0.0001227851607836783\n",
      "Steps : 21900, \t Total Gen Loss : 28.886211395263672, \t Total Dis Loss : 8.193972462322563e-05\n",
      "Steps : 22000, \t Total Gen Loss : 22.88263511657715, \t Total Dis Loss : 0.0001116757994168438\n",
      "Steps : 22100, \t Total Gen Loss : 26.123647689819336, \t Total Dis Loss : 0.00016509764827787876\n",
      "Steps : 22200, \t Total Gen Loss : 24.464691162109375, \t Total Dis Loss : 0.0005444013513624668\n",
      "Steps : 22300, \t Total Gen Loss : 25.448198318481445, \t Total Dis Loss : 0.0001431400451110676\n",
      "Steps : 22400, \t Total Gen Loss : 25.17182159423828, \t Total Dis Loss : 8.079205872491002e-05\n",
      "Steps : 22500, \t Total Gen Loss : 23.915863037109375, \t Total Dis Loss : 0.00011233898840146139\n",
      "Time for epoch 4 is 272.41143679618835 sec\n",
      "Steps : 22600, \t Total Gen Loss : 30.02429962158203, \t Total Dis Loss : 0.00021473677770700306\n",
      "Steps : 22700, \t Total Gen Loss : 27.296106338500977, \t Total Dis Loss : 0.00015716333291493356\n",
      "Steps : 22800, \t Total Gen Loss : 25.633159637451172, \t Total Dis Loss : 0.0004834196297451854\n",
      "Steps : 22900, \t Total Gen Loss : 27.32508087158203, \t Total Dis Loss : 0.0005659098387695849\n",
      "Steps : 23000, \t Total Gen Loss : 24.878904342651367, \t Total Dis Loss : 0.0003959007153753191\n",
      "Steps : 23100, \t Total Gen Loss : 26.984054565429688, \t Total Dis Loss : 0.0001553259207867086\n",
      "Steps : 23200, \t Total Gen Loss : 24.604516983032227, \t Total Dis Loss : 0.00015392558998428285\n",
      "Steps : 23300, \t Total Gen Loss : 28.685813903808594, \t Total Dis Loss : 4.169503154116683e-05\n",
      "Steps : 23400, \t Total Gen Loss : 29.70818328857422, \t Total Dis Loss : 0.00045748072443529963\n",
      "Steps : 23500, \t Total Gen Loss : 26.268596649169922, \t Total Dis Loss : 0.000295179255772382\n",
      "Steps : 23600, \t Total Gen Loss : 26.320409774780273, \t Total Dis Loss : 0.00016634949133731425\n",
      "Steps : 23700, \t Total Gen Loss : 27.13912010192871, \t Total Dis Loss : 0.0005754107842221856\n",
      "Steps : 23800, \t Total Gen Loss : 28.121105194091797, \t Total Dis Loss : 0.00014002200623508543\n",
      "Steps : 23900, \t Total Gen Loss : 24.04132652282715, \t Total Dis Loss : 0.0001525611151009798\n",
      "Steps : 24000, \t Total Gen Loss : 26.477005004882812, \t Total Dis Loss : 0.00017922781989909708\n",
      "Steps : 24100, \t Total Gen Loss : 25.648286819458008, \t Total Dis Loss : 0.000151839034515433\n",
      "Steps : 24200, \t Total Gen Loss : 25.725406646728516, \t Total Dis Loss : 6.935470446478575e-05\n",
      "Steps : 24300, \t Total Gen Loss : 29.777997970581055, \t Total Dis Loss : 5.510736446012743e-05\n",
      "Steps : 24400, \t Total Gen Loss : 27.311891555786133, \t Total Dis Loss : 9.975752618629485e-05\n",
      "Steps : 24500, \t Total Gen Loss : 26.483203887939453, \t Total Dis Loss : 0.00012855447130277753\n",
      "Steps : 24600, \t Total Gen Loss : 25.578018188476562, \t Total Dis Loss : 7.51744446461089e-05\n",
      "Steps : 24700, \t Total Gen Loss : 28.61019515991211, \t Total Dis Loss : 0.00017144999583251774\n",
      "Steps : 24800, \t Total Gen Loss : 24.842864990234375, \t Total Dis Loss : 0.00016792595852166414\n",
      "Steps : 24900, \t Total Gen Loss : 27.675987243652344, \t Total Dis Loss : 0.0005815309705212712\n",
      "Steps : 25000, \t Total Gen Loss : 25.60346221923828, \t Total Dis Loss : 8.97985155461356e-05\n",
      "Steps : 25100, \t Total Gen Loss : 25.676315307617188, \t Total Dis Loss : 0.00035232282243669033\n",
      "Steps : 25200, \t Total Gen Loss : 29.11686134338379, \t Total Dis Loss : 3.733274570549838e-05\n",
      "Steps : 25300, \t Total Gen Loss : 23.433656692504883, \t Total Dis Loss : 0.00654261838644743\n",
      "Steps : 25400, \t Total Gen Loss : 26.58519172668457, \t Total Dis Loss : 4.859928594669327e-05\n",
      "Steps : 25500, \t Total Gen Loss : 27.687437057495117, \t Total Dis Loss : 4.885179805569351e-05\n",
      "Steps : 25600, \t Total Gen Loss : 26.245725631713867, \t Total Dis Loss : 3.854937313008122e-05\n",
      "Steps : 25700, \t Total Gen Loss : 31.76405906677246, \t Total Dis Loss : 0.00011275755969109014\n",
      "Steps : 25800, \t Total Gen Loss : 27.919532775878906, \t Total Dis Loss : 0.00012348699965514243\n",
      "Steps : 25900, \t Total Gen Loss : 25.710485458374023, \t Total Dis Loss : 0.0006180258351378143\n",
      "Steps : 26000, \t Total Gen Loss : 29.30255699157715, \t Total Dis Loss : 0.00045335121103562415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 26100, \t Total Gen Loss : 28.634815216064453, \t Total Dis Loss : 0.0005208835937082767\n",
      "Steps : 26200, \t Total Gen Loss : 28.341089248657227, \t Total Dis Loss : 0.0004232387582305819\n",
      "Steps : 26300, \t Total Gen Loss : 30.55772590637207, \t Total Dis Loss : 9.993785351980478e-05\n",
      "Steps : 26400, \t Total Gen Loss : 29.10812759399414, \t Total Dis Loss : 0.0012847951147705317\n",
      "Steps : 26500, \t Total Gen Loss : 25.634307861328125, \t Total Dis Loss : 0.003317257622256875\n",
      "Steps : 26600, \t Total Gen Loss : 25.94975471496582, \t Total Dis Loss : 0.00033227595849893987\n",
      "Steps : 26700, \t Total Gen Loss : 28.958904266357422, \t Total Dis Loss : 0.0005574804381467402\n",
      "Steps : 26800, \t Total Gen Loss : 30.20517349243164, \t Total Dis Loss : 4.613501369021833e-05\n",
      "Steps : 26900, \t Total Gen Loss : 30.466785430908203, \t Total Dis Loss : 0.0001448128023184836\n",
      "Steps : 27000, \t Total Gen Loss : 28.409177780151367, \t Total Dis Loss : 0.0015518636209890246\n",
      "Steps : 27100, \t Total Gen Loss : 28.91691780090332, \t Total Dis Loss : 0.0003740643442142755\n",
      "Steps : 27200, \t Total Gen Loss : 28.412391662597656, \t Total Dis Loss : 0.0001121105597121641\n",
      "Steps : 27300, \t Total Gen Loss : 32.16746139526367, \t Total Dis Loss : 0.0003014160320162773\n",
      "Steps : 27400, \t Total Gen Loss : 30.475494384765625, \t Total Dis Loss : 0.0028244939167052507\n",
      "Steps : 27500, \t Total Gen Loss : 27.622272491455078, \t Total Dis Loss : 0.0003057529975194484\n",
      "Steps : 27600, \t Total Gen Loss : 27.980785369873047, \t Total Dis Loss : 0.00020369600679259747\n",
      "Steps : 27700, \t Total Gen Loss : 30.270265579223633, \t Total Dis Loss : 9.880815196083859e-05\n",
      "Steps : 27800, \t Total Gen Loss : 28.904678344726562, \t Total Dis Loss : 0.0011455093044787645\n",
      "Steps : 27900, \t Total Gen Loss : 28.127416610717773, \t Total Dis Loss : 0.00037444906774908304\n",
      "Steps : 28000, \t Total Gen Loss : 24.985069274902344, \t Total Dis Loss : 0.00015269755385816097\n",
      "Steps : 28100, \t Total Gen Loss : 30.384662628173828, \t Total Dis Loss : 0.00028533197473734617\n",
      "Time for epoch 5 is 278.41400599479675 sec\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "steps = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for images, labels in train_dataset:\n",
    "        steps += 1\n",
    "        gen_loss, disc_loss = train_step(images)\n",
    "        \n",
    "        if steps % 100 == 0:\n",
    "            print ('Steps : {}, \\t Total Gen Loss : {}, \\t Total Dis Loss : {}'.format(steps, gen_loss.numpy(), disc_loss.numpy()))\n",
    "        \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        checkpoint.save(checkpoint_path)\n",
    "        \n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7ff41a4b0150>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate(test_dataset, set_lambda=0.9):\n",
    "    an_scores = []\n",
    "    gt_labels = []\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(test_dataset):\n",
    "        generated_images = generator(x_batch_train, training=True)\n",
    "        _, feat_real = discriminator(x_batch_train, training=True)\n",
    "        _, feat_fake = discriminator(generated_images, training=True)\n",
    "\n",
    "        generated_images, feat_real, feat_fake = generated_images.numpy(), feat_real.numpy(), feat_fake.numpy()        \n",
    "\n",
    "        rec = abs(x_batch_train - generated_images)\n",
    "        lat = (feat_real - feat_fake) ** 2\n",
    "\n",
    "        rec = tf.reduce_sum(rec, [1,2,3])\n",
    "        lat = tf.reduce_sum(lat, [1,2,3])\n",
    "        \n",
    "        error = (set_lambda * tf.cast(rec, tf.float32)) + ((1 - set_lambda) * tf.cast(lat, tf.float32))\n",
    "        \n",
    "        an_scores.append(error)\n",
    "        gt_labels.append(y_batch_train)\n",
    "        \n",
    "    an_scores = np.concatenate(an_scores, axis=0).reshape([-1])\n",
    "    gt_labels = np.concatenate(gt_labels, axis=0).reshape([-1])\n",
    "    \n",
    "    an_scores = (an_scores - np.amin(an_scores)) / (np.amax(an_scores) - np.amin(an_scores))\n",
    "    \n",
    "    return an_scores, gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 15000\n"
     ]
    }
   ],
   "source": [
    "an_scores, gt_labels = _evaluate(test_dataset)\n",
    "\n",
    "print(len(an_scores), len(gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000,)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "normal = []\n",
    "anormaly = []\n",
    "for score, label in zip(an_scores, gt_labels):\n",
    "    if label == 0:\n",
    "        anormaly.append(score)\n",
    "    else:\n",
    "        normal.append(score)\n",
    "\n",
    "normal = np.array(normal)\n",
    "print(normal.shape)\n",
    "anormaly = np.array(anormaly)\n",
    "print(anormaly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normal, bins=np.linspace(0.0, 1.0, num=100))\n",
    "plt.hist(anormaly, bins=np.linspace(0.0, 1.0, num=100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3252508 0.2992694\n",
      "0.12729788 0.11795122\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(normal, norm.pdf(normal, np.mean(normal), np.std(normal)), 'o')\n",
    "plt.plot(anormaly, norm.pdf(anormaly, np.mean(anormaly), np.std(anormaly)), 'o')\n",
    "\n",
    "print(np.mean(normal), np.mean(anormaly))\n",
    "print(np.std(normal), np.std(anormaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 만들고 학습가지 시켜보았습니다! \n",
    "\n",
    "normal 데이터와 anomaly 데이터의 분포 차이가 있습니다. 개구리 사진이 나오면 이상하다고 잘 탐지할 수 있겠죠?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
